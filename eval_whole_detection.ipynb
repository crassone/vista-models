{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a48ff72b-f9a4-4b6a-9c8c-fb5a170fdee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e92d2dc-c07e-40d2-9af5-49a0861bb2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_date = '2023-12-24'\n",
    "root_dir = os.getcwd()\n",
    "annotation_path = f'{root_dir}/data/outputs/01.format_and_cv/annotation-{pattern_date}.csv'\n",
    "helmet_path = f'{root_dir}/data/outputs/03.helmet_detection/03.eval_coatnet_cls7_use_anno/pred_head_class-{pattern_date}.csv'\n",
    "highplace_path = f'{root_dir}/data/outputs/04.highplace_detection/06.kosmos2_pred_highplace_detection/pred_highplace_class-{pattern_date}.csv'\n",
    "safetybelt_path = f'{root_dir}/data/outputs/05.safetybelt_detection/02.eval_coatnet_cls3_use_anno/pred_safetybelt_class-{pattern_date}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0560d4a8-a40b-4ce2-9b9e-e9a35b4def36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_intersection_per_label(pred_bbox, label_bbox):\n",
    "    # バウンディングボックスの座標情報を取得\n",
    "    x1_1, y1_1, x2_1, y2_1 = label_bbox\n",
    "    x1_2, y1_2, x2_2, y2_2 = pred_bbox\n",
    "\n",
    "    # 交差する領域を計算\n",
    "    x_intersection = max(0, min(x2_1, x2_2) - max(x1_1, x1_2))\n",
    "    y_intersection = max(0, min(y2_1, y2_2) - max(y1_1, y1_2))\n",
    "    intersection_area = x_intersection * y_intersection\n",
    "\n",
    "    # 正解ラベルの面積\n",
    "    area_label_bbox = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
    "\n",
    "    # 交差する領域の面積 / 正解ラベルの面積\n",
    "    return intersection_area / area_label_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e5f0e02-7b90-4448-938f-4f2e16297d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(box1, box2):\n",
    "    # バウンディングボックスの座標情報を取得\n",
    "    x1_1, y1_1, x2_1, y2_1 = box1\n",
    "    x1_2, y1_2, x2_2, y2_2 = box2\n",
    "\n",
    "    # 交差する領域を計算\n",
    "    x_intersection = max(0, min(x2_1, x2_2) - max(x1_1, x1_2))\n",
    "    y_intersection = max(0, min(y2_1, y2_2) - max(y1_1, y1_2))\n",
    "\n",
    "    # 交差領域の面積と各バウンディングボックスの面積を計算\n",
    "    intersection_area = x_intersection * y_intersection\n",
    "    area_box1 = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
    "    area_box2 = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
    "\n",
    "    # IoUを計算\n",
    "    iou = intersection_area / (area_box1 + area_box2 - intersection_area)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44584418-ccdb-4bc3-a688-ce54466a9ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_annotation_df = pd.read_csv(annotation_path)\n",
    "all_helmet_df = pd.read_csv(helmet_path)\n",
    "all_highplace_df = pd.read_csv(highplace_path)\n",
    "all_safetybelt_df = pd.read_csv(safetybelt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b116af61-f6d2-470b-9ba6-2128deab9a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_df = all_annotation_df[\n",
    "    (all_annotation_df['unique_key'].str.contains('fixed-point-camera')) |\n",
    "    (all_annotation_df['unique_key'].str.contains('for-learning/2023-11-19-omaezaki-500')) |\n",
    "    (all_annotation_df['unique_key'].str.contains('for-learning/2023-11-23-mie-safetybelt')) |\n",
    "    (all_annotation_df['unique_key'].str.contains('evaluation'))\n",
    "]\n",
    "\n",
    "helmet_df = all_helmet_df[\n",
    "    (all_helmet_df['unique_key'].str.contains('fixed-point-camera')) |\n",
    "    (all_helmet_df['unique_key'].str.contains('for-learning/2023-11-19-omaezaki-500')) |\n",
    "    (all_helmet_df['unique_key'].str.contains('for-learning/2023-11-23-mie-safetybelt')) |\n",
    "    (all_helmet_df['unique_key'].str.contains('evaluation'))\n",
    "]\n",
    "\n",
    "highplace_df = all_highplace_df[\n",
    "    (all_highplace_df['unique_key'].str.contains('fixed-point-camera')) |\n",
    "    (all_highplace_df['unique_key'].str.contains('for-learning/2023-11-19-omaezaki-500')) |\n",
    "    (all_highplace_df['unique_key'].str.contains('for-learning/2023-11-23-mie-safetybelt')) |\n",
    "    (all_highplace_df['unique_key'].str.contains('evaluation'))\n",
    "]\n",
    "\n",
    "safetybelt_df = all_safetybelt_df[\n",
    "    (all_safetybelt_df['unique_key'].str.contains('fixed-point-camera')) |\n",
    "    (all_safetybelt_df['unique_key'].str.contains('for-learning/2023-11-19-omaezaki-500')) |\n",
    "    (all_safetybelt_df['unique_key'].str.contains('for-learning/2023-11-23-mie-safetybelt')) |\n",
    "    (all_safetybelt_df['unique_key'].str.contains('evaluation'))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e25b841f-43af-4411-b6e1-bef673f976ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2855237/2670705351.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  annotation_df['label'] = new_label_list\n"
     ]
    }
   ],
   "source": [
    "iou_threshold = 0.1\n",
    "annotation_safetybelt_df = annotation_df[annotation_df[\"label\"] == 'safety belt']\n",
    "\n",
    "new_label_list = []\n",
    "for i, info_df in enumerate(annotation_df.values):\n",
    "    label = info_df[2]\n",
    "    if label not in ['person', 'person in high place']:\n",
    "        new_label_list += [label]\n",
    "        continue\n",
    "\n",
    "    unique_key = info_df[0]\n",
    "    person_bbox = info_df[3:7]\n",
    "    safetybelt_bboxes = annotation_safetybelt_df[\n",
    "        annotation_safetybelt_df['unique_key'] == unique_key\n",
    "    ][['left', 'top', 'right', 'bottom']].values\n",
    "\n",
    "    is_label_safetybelt = False\n",
    "    for safetybelt_bbox in safetybelt_bboxes:\n",
    "        iou = calculate_iou(person_bbox, safetybelt_bbox)\n",
    "        if iou > iou_threshold:\n",
    "            new_label_list += [f'{label} - safetybelt']\n",
    "            is_label_safetybelt = True\n",
    "            break\n",
    "    if not is_label_safetybelt:\n",
    "        new_label_list += [f'{label} - no-safetybelt']\n",
    "\n",
    "annotation_df['label'] = new_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8829ab38-8d7b-4868-8ca8-7fec062cf385",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_image = pd.DataFrame(annotation_df['unique_key'].unique(), columns=['unique_key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d487200-d687-4a3c-bda2-baa9a71c3668",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_labels = []\n",
    "for unique_key in annotation_df['unique_key'].unique():\n",
    "    _annotation_df = annotation_df[annotation_df['unique_key'] == unique_key]\n",
    "\n",
    "    has_unique_key_labels = []\n",
    "    for pred in annotation_df['label'].unique():\n",
    "        if pd.isna(pred):\n",
    "            continue\n",
    "        if len(_annotation_df[_annotation_df['label'] == pred]) > 0:\n",
    "            has_unique_key_labels += [True]\n",
    "        else:\n",
    "            has_unique_key_labels += [False]\n",
    "    has_labels += [has_unique_key_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35ecbae5-d151-435e-929e-037e35bbb73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_image[[f'label_{i}' for i in annotation_df['label'].unique() if pd.notna(i)]] = has_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27f1cd27-a593-4bd4-b0ee-2623828f6dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_helmet_pred = []\n",
    "for unique_key in annotation_df['unique_key'].unique():\n",
    "    _helmet_df = helmet_df[helmet_df['unique_key'] == unique_key]\n",
    "\n",
    "    has_unique_key_labels = []\n",
    "    for pred in helmet_df['pred_head_class'].unique():\n",
    "        if len(_helmet_df[_helmet_df['pred_head_class'] == pred]) > 0:\n",
    "            has_unique_key_labels += [True]\n",
    "        else:\n",
    "            has_unique_key_labels += [False]\n",
    "    has_helmet_pred += [has_unique_key_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "822ae821-c183-4b06-aef4-e80fbd108ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_image[[f'pred_helmet_{i}' for i in helmet_df['pred_head_class'].unique()]] = has_helmet_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adca073e-5c4c-468f-ba3a-df34119558b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "highplace_safetybelt_df = pd.concat([highplace_df, safetybelt_df[['pred_safetybelt_class']]], axis=1)\n",
    "highplace_safetybelt_df['pred_alart'] = highplace_safetybelt_df['pred_person_in_highplace_class'] + ' - ' + highplace_safetybelt_df['pred_safetybelt_class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36e7e861-52e6-4496-b68d-b6e5de088344",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_highplace_safetybelt_pred = []\n",
    "for unique_key in annotation_df['unique_key'].unique():\n",
    "    _highplace_safetybelt_df = highplace_safetybelt_df[highplace_safetybelt_df['unique_key'] == unique_key]\n",
    "\n",
    "    has_unique_key_labels = []\n",
    "    for pred in highplace_safetybelt_df['pred_alart'].unique():\n",
    "        if len(_highplace_safetybelt_df[_highplace_safetybelt_df['pred_alart'] == pred]) > 0:\n",
    "            has_unique_key_labels += [True]\n",
    "        else:\n",
    "            has_unique_key_labels += [False]\n",
    "    has_highplace_safetybelt_pred += [has_unique_key_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cac5e98-a48a-41da-a37d-e7a6a2d43bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_image[[f'pred_highsafe_{i}' for i in highplace_safetybelt_df['pred_alart'].unique()]] = has_highplace_safetybelt_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d32abb01-2af6-4d48-a611-bf7fa270be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_image = pd.merge(\n",
    "    df_per_image, annotation_df[['unique_key', 'validation']].drop_duplicates(), on='unique_key'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4dea86e9-b011-49af-a69b-00610d2522d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_helmet_alart(row):\n",
    "    if (\n",
    "        row['label_no-helmet'] or\n",
    "        row['label_unsafe-helmet (no chin strap)'] or\n",
    "        row['label_unsafe-helmet (inadequate covering)']\n",
    "    ):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def pred_helmet_alart(row):\n",
    "    if (\n",
    "        row['pred_helmet_no-helmet'] or\n",
    "        row['pred_helmet_unsafe-helmet (no chin strap)'] or\n",
    "        row['pred_helmet_unsafe-helmet (inadequate covering)']\n",
    "    ):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def label_highplace_safetybelt_alart(row):\n",
    "    if row['label_person in high place - no-safetybelt']:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def pred_highplace_safetybelt_alart(row):\n",
    "    if row['pred_highsafe_person in high place - no-safetybelt']:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def label_alart(row):\n",
    "    if row['label_helmet_alart'] or row['label_highplace_safetybelt_alart']:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def pred_alart(row):\n",
    "    if row['pred_helmet_alart'] or row['pred_highplace_safetybelt_alart']:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d791b41e-c67f-4bca-8465-8c0d52154fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_df = copy.deepcopy(df_per_image[['unique_key', 'validation']])\n",
    "evaluation_df['label_helmet_alart'] = df_per_image.apply(label_helmet_alart, axis=1)\n",
    "evaluation_df['pred_helmet_alart'] = df_per_image.apply(pred_helmet_alart, axis=1)\n",
    "evaluation_df['label_highplace_safetybelt_alart'] = df_per_image.apply(label_highplace_safetybelt_alart, axis=1)\n",
    "evaluation_df['pred_highplace_safetybelt_alart'] = df_per_image.apply(pred_highplace_safetybelt_alart, axis=1)\n",
    "evaluation_df['label_alart'] = evaluation_df.apply(label_alart, axis=1)\n",
    "evaluation_df['pred_alart'] = evaluation_df.apply(pred_alart, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a76012c2-8545-44f8-a0c4-60cb1a63fb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_val_df = evaluation_df[evaluation_df['validation'] != 999]\n",
    "evaluation_test_df = evaluation_df[evaluation_df['validation'] == 999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf931938-66cd-4f61-9069-7e3a9b11f4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習用データ\n",
      "precision: 0.9842931937172775\n",
      "recall:    0.35946462715105165\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>予測 - アラートなし</th>\n",
       "      <th>予測 - アラートあり</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>正解 - アラートなし</th>\n",
       "      <td>453.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>正解 - アラートあり</th>\n",
       "      <td>670.0</td>\n",
       "      <td>376.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             予測 - アラートなし  予測 - アラートあり\n",
       "正解 - アラートなし        453.0          6.0\n",
       "正解 - アラートあり        670.0        376.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "評価用データ\n",
      "precision: 1.0\n",
      "recall:    0.26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>予測 - アラートなし</th>\n",
       "      <th>予測 - アラートあり</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>正解 - アラートなし</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>正解 - アラートあり</th>\n",
       "      <td>37.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             予測 - アラートなし  予測 - アラートあり\n",
       "正解 - アラートなし         40.0          0.0\n",
       "正解 - アラートあり         37.0         13.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_mat = np.zeros([2, 2])\n",
    "for label, pred in evaluation_val_df[['label_alart', 'pred_alart']].values:\n",
    "    if label == False and pred == False:\n",
    "        confusion_mat[0][0] += 1\n",
    "    if label == False and pred == True:\n",
    "        confusion_mat[0][1] += 1\n",
    "    if label == True and pred == False:\n",
    "        confusion_mat[1][0] += 1\n",
    "    if label == True and pred == True:\n",
    "        confusion_mat[1][1] += 1\n",
    "\n",
    "print('学習用データ')\n",
    "print(f'precision: {confusion_mat[1][1] / (confusion_mat[0][1] + confusion_mat[1][1])}')\n",
    "print(f'recall:    {confusion_mat[1][1] / (confusion_mat[1][0] + confusion_mat[1][1])}')\n",
    "display(\n",
    "    pd.DataFrame(\n",
    "        confusion_mat,\n",
    "        index = [f'正解 - {i}' for i in ['アラートなし', 'アラートあり']],\n",
    "        columns=[f'予測 - {i}' for i in ['アラートなし', 'アラートあり']]\n",
    "    )\n",
    ")\n",
    "\n",
    "confusion_mat = np.zeros([2, 2])\n",
    "for label, pred in evaluation_test_df[['label_alart', 'pred_alart']].values:\n",
    "    if label == False and pred == False:\n",
    "        confusion_mat[0][0] += 1\n",
    "    if label == False and pred == True:\n",
    "        confusion_mat[0][1] += 1\n",
    "    if label == True and pred == False:\n",
    "        confusion_mat[1][0] += 1\n",
    "    if label == True and pred == True:\n",
    "        confusion_mat[1][1] += 1\n",
    "\n",
    "print('評価用データ')\n",
    "print(f'precision: {confusion_mat[1][1] / (confusion_mat[0][1] + confusion_mat[1][1])}')\n",
    "print(f'recall:    {confusion_mat[1][1] / (confusion_mat[1][0] + confusion_mat[1][1])}')\n",
    "display(\n",
    "    pd.DataFrame(\n",
    "        confusion_mat,\n",
    "        index = [f'正解 - {i}' for i in ['アラートなし', 'アラートあり']],\n",
    "        columns=[f'予測 - {i}' for i in ['アラートなし', 'アラートあり']]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84a0a540-9617-494e-a87f-2c2738993390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習用データ: ヘルメットアラート\n",
      "precision: 0.9842105263157894\n",
      "recall:    0.38556701030927837\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>予測 - アラートなし</th>\n",
       "      <th>予測 - アラートあり</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>正解 - アラートなし</th>\n",
       "      <td>529.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>正解 - アラートあり</th>\n",
       "      <td>596.0</td>\n",
       "      <td>374.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             予測 - アラートなし  予測 - アラートあり\n",
       "正解 - アラートなし        529.0          6.0\n",
       "正解 - アラートあり        596.0        374.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "評価用データ: ヘルメットアラート\n",
      "precision: 1.0\n",
      "recall:    0.1891891891891892\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>予測 - アラートなし</th>\n",
       "      <th>予測 - アラートあり</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>正解 - アラートなし</th>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>正解 - アラートあり</th>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             予測 - アラートなし  予測 - アラートあり\n",
       "正解 - アラートなし         53.0          0.0\n",
       "正解 - アラートあり         30.0          7.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_mat = np.zeros([2, 2])\n",
    "for label, pred in evaluation_val_df[['label_helmet_alart', 'pred_helmet_alart']].values:\n",
    "    if label == False and pred == False:\n",
    "        confusion_mat[0][0] += 1\n",
    "    if label == False and pred == True:\n",
    "        confusion_mat[0][1] += 1\n",
    "    if label == True and pred == False:\n",
    "        confusion_mat[1][0] += 1\n",
    "    if label == True and pred == True:\n",
    "        confusion_mat[1][1] += 1\n",
    "\n",
    "print('学習用データ: ヘルメットアラート')\n",
    "print(f'precision: {confusion_mat[1][1] / (confusion_mat[0][1] + confusion_mat[1][1])}')\n",
    "print(f'recall:    {confusion_mat[1][1] / (confusion_mat[1][0] + confusion_mat[1][1])}')\n",
    "display(\n",
    "    pd.DataFrame(\n",
    "        confusion_mat,\n",
    "        index = [f'正解 - {i}' for i in ['アラートなし', 'アラートあり']],\n",
    "        columns=[f'予測 - {i}' for i in ['アラートなし', 'アラートあり']]\n",
    "    )\n",
    ")\n",
    "\n",
    "confusion_mat = np.zeros([2, 2])\n",
    "for label, pred in evaluation_test_df[['label_helmet_alart', 'pred_helmet_alart']].values:\n",
    "    if label == False and pred == False:\n",
    "        confusion_mat[0][0] += 1\n",
    "    if label == False and pred == True:\n",
    "        confusion_mat[0][1] += 1\n",
    "    if label == True and pred == False:\n",
    "        confusion_mat[1][0] += 1\n",
    "    if label == True and pred == True:\n",
    "        confusion_mat[1][1] += 1\n",
    "\n",
    "print('評価用データ: ヘルメットアラート')\n",
    "print(f'precision: {confusion_mat[1][1] / (confusion_mat[0][1] + confusion_mat[1][1])}')\n",
    "print(f'recall:    {confusion_mat[1][1] / (confusion_mat[1][0] + confusion_mat[1][1])}')\n",
    "display(\n",
    "    pd.DataFrame(\n",
    "        confusion_mat,\n",
    "        index = [f'正解 - {i}' for i in ['アラートなし', 'アラートあり']],\n",
    "        columns=[f'予測 - {i}' for i in ['アラートなし', 'アラートあり']]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3178975d-4783-4268-8e41-f779e1c7343d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習用データ: 安全帯アラート\n",
      "precision: 1.0\n",
      "recall:    0.022727272727272728\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>予測 - アラートなし</th>\n",
       "      <th>予測 - アラートあり</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>正解 - アラートなし</th>\n",
       "      <td>1417.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>正解 - アラートあり</th>\n",
       "      <td>86.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             予測 - アラートなし  予測 - アラートあり\n",
       "正解 - アラートなし       1417.0          0.0\n",
       "正解 - アラートあり         86.0          2.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "評価用データ: 安全帯アラート\n",
      "precision: 0.6666666666666666\n",
      "recall:    0.16666666666666666\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>予測 - アラートなし</th>\n",
       "      <th>予測 - アラートあり</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>正解 - アラートなし</th>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>正解 - アラートあり</th>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             予測 - アラートなし  予測 - アラートあり\n",
       "正解 - アラートなし         64.0          2.0\n",
       "正解 - アラートあり         20.0          4.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_mat = np.zeros([2, 2])\n",
    "for label, pred in evaluation_val_df[['label_highplace_safetybelt_alart', 'pred_highplace_safetybelt_alart']].values:\n",
    "    if label == False and pred == False:\n",
    "        confusion_mat[0][0] += 1\n",
    "    if label == False and pred == True:\n",
    "        confusion_mat[0][1] += 1\n",
    "    if label == True and pred == False:\n",
    "        confusion_mat[1][0] += 1\n",
    "    if label == True and pred == True:\n",
    "        confusion_mat[1][1] += 1\n",
    "\n",
    "print('学習用データ: 安全帯アラート')\n",
    "print(f'precision: {confusion_mat[1][1] / (confusion_mat[0][1] + confusion_mat[1][1])}')\n",
    "print(f'recall:    {confusion_mat[1][1] / (confusion_mat[1][0] + confusion_mat[1][1])}')\n",
    "display(\n",
    "    pd.DataFrame(\n",
    "        confusion_mat,\n",
    "        index = [f'正解 - {i}' for i in ['アラートなし', 'アラートあり']],\n",
    "        columns=[f'予測 - {i}' for i in ['アラートなし', 'アラートあり']]\n",
    "    )\n",
    ")\n",
    "\n",
    "confusion_mat = np.zeros([2, 2])\n",
    "for label, pred in evaluation_test_df[['label_highplace_safetybelt_alart', 'pred_highplace_safetybelt_alart']].values:\n",
    "    if label == False and pred == False:\n",
    "        confusion_mat[0][0] += 1\n",
    "    if label == False and pred == True:\n",
    "        confusion_mat[0][1] += 1\n",
    "    if label == True and pred == False:\n",
    "        confusion_mat[1][0] += 1\n",
    "    if label == True and pred == True:\n",
    "        confusion_mat[1][1] += 1\n",
    "\n",
    "print('評価用データ: 安全帯アラート')\n",
    "print(f'precision: {confusion_mat[1][1] / (confusion_mat[0][1] + confusion_mat[1][1])}')\n",
    "print(f'recall:    {confusion_mat[1][1] / (confusion_mat[1][0] + confusion_mat[1][1])}')\n",
    "display(\n",
    "    pd.DataFrame(\n",
    "        confusion_mat,\n",
    "        index = [f'正解 - {i}' for i in ['アラートなし', 'アラートあり']],\n",
    "        columns=[f'予測 - {i}' for i in ['アラートなし', 'アラートあり']]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1807d3db-3823-40ad-b504-8868066dc248",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
